{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f384e6-d978-4197-ab67-e40c87ac486c",
   "metadata": {},
   "source": [
    "Practical 06 : Write a python program to recognize the numbers 0, 1, 2, 39. A 5 * 3 matrix forms the numbers. For\n",
    "any valid point it is taken as 1 and invalid point it is taken as 0. The net has to be trained to recognize\n",
    "all the numbers and when the test data is given, the network has to recognize the particular numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a3b41e4-dad7-4be2-867f-18450cb5151a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output after training:\n",
      "[[0.01144951]\n",
      " [0.03600105]\n",
      " [0.03600103]\n",
      " [0.95450214]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Training data for AND\n",
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "outputs = np.array([[0], [0], [0], [1]])\n",
    "\n",
    "# Initialize weights and biases\n",
    "np.random.seed(1)\n",
    "input_layer_neurons = 2 # Input layer (2 inputs)\n",
    "hidden_layer_neurons = 1 # Hidden layer (1 neuron)\n",
    "output_neurons = 1 # Output layer (1 output)\n",
    "\n",
    "weights_input_hidden = np.random.uniform(size=(input_layer_neurons, hidden_layer_neurons))\n",
    "weights_hidden_output = np.random.uniform(size=(hidden_layer_neurons, output_neurons))\n",
    "\n",
    "bias_hidden = np.random.uniform(size=(1, hidden_layer_neurons))\n",
    "bias_output = np.random.uniform(size=(1, output_neurons))\n",
    "\n",
    "# Training parameters\n",
    "epochs = 10000\n",
    "learning_rate = 0.1\n",
    "\n",
    "# Training process\n",
    "for epoch in range(epochs):\n",
    "    # Forward Propagation\n",
    "    hidden_layer_activation = np.dot(inputs, weights_input_hidden) + bias_hidden\n",
    "    hidden_layer_output = sigmoid(hidden_layer_activation)\n",
    "    \n",
    "    output_layer_activation = np.dot(hidden_layer_output, weights_hidden_output) + bias_output\n",
    "    predicted_output = sigmoid(output_layer_activation)\n",
    "    \n",
    "    # Backpropagation\n",
    "    error = outputs - predicted_output\n",
    "    d_predicted_output = error * sigmoid_derivative(predicted_output)\n",
    "    \n",
    "    error_hidden_layer = d_predicted_output.dot(weights_hidden_output.T)\n",
    "    d_hidden_layer = error_hidden_layer * sigmoid_derivative(hidden_layer_output)\n",
    "    \n",
    "    # Updating Weights and Biases\n",
    "    weights_hidden_output += hidden_layer_output.T.dot(d_predicted_output) * learning_rate\n",
    "    bias_output += np.sum(d_predicted_output, axis=0, keepdims=True) * learning_rate\n",
    "    weights_input_hidden += inputs.T.dot(d_hidden_layer) * learning_rate\n",
    "    bias_hidden += np.sum(d_hidden_layer, axis=0, keepdims=True) * learning_rate\n",
    "\n",
    "# Final output after training\n",
    "print('Output after training:')\n",
    "print(predicted_output)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9c4cb5-af54-459a-9345-2419b4165c24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
